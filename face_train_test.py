"""
model_reset_tool_fixed.py - æ¨¡å‹é‡ç½®å’Œä¿®å¤å·¥å…·ï¼ˆä¿®å¤ç‰ˆï¼‰
è§£å†³TensorFlowå…¼å®¹æ€§é—®é¢˜
"""

import os
import shutil
import tensorflow.compat.v1 as tf
import numpy as np
import cv2
from sklearn.model_selection import train_test_split
import random
import glob
import matplotlib.pyplot as plt

# ç¦ç”¨TensorFlow 2.xè¡Œä¸ºï¼Œå¯ç”¨v1å…¼å®¹æ¨¡å¼
tf.disable_v2_behavior()
tf.disable_eager_execution()


def reset_and_retrain():
    """é‡ç½®å¹¶é‡æ–°è®­ç»ƒæ¨¡å‹"""
    print("=" * 60)
    print("    æ¨¡å‹é‡ç½®å’Œä¿®å¤å·¥å…·ï¼ˆä¿®å¤ç‰ˆï¼‰")
    print("=" * 60)

    # åˆ é™¤æ—§æ¨¡å‹
    model_dir = './model_fixed'
    if os.path.exists(model_dir):
        print(f"ğŸ—‘ï¸  åˆ é™¤æ—§æ¨¡å‹ç›®å½•: {model_dir}")
        shutil.rmtree(model_dir)

    # åˆ›å»ºæ–°æ¨¡å‹ç›®å½•
    os.makedirs(model_dir, exist_ok=True)

    # é‡æ–°è®­ç»ƒ
    return train_fixed_model()


def verify_data():
    """éªŒè¯æ•°æ®æ­£ç¡®æ€§"""
    print("\nğŸ” éªŒè¯è®­ç»ƒæ•°æ®...")

    # æ£€æŸ¥ç”¨æˆ·æ•°æ®
    user_dir = './faces_user'
    if not os.path.exists(user_dir):
        print(f"âŒ ç”¨æˆ·æ•°æ®ç›®å½•ä¸å­˜åœ¨: {user_dir}")
        return False

    user_count = 0
    user_subdirs = []
    for item in os.listdir(user_dir):
        item_path = os.path.join(user_dir, item)
        if os.path.isdir(item_path):
            files = [f for f in os.listdir(item_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
            user_count += len(files)
            user_subdirs.append((item, len(files)))

    print(f"   ç”¨æˆ·æ•°æ®: {user_count} å¼ å›¾ç‰‡")
    for subdir, count in user_subdirs:
        print(f"     - {subdir}: {count} å¼ ")

    # æ£€æŸ¥é™Œç”Ÿäººæ•°æ®
    stranger_dir = './faces_strangers'
    if not os.path.exists(stranger_dir):
        print(f"âš ï¸ é™Œç”Ÿäººæ•°æ®ç›®å½•ä¸å­˜åœ¨: {stranger_dir}")
        stranger_count = 0
    else:
        stranger_count = 0
        for item in os.listdir(stranger_dir):
            item_path = os.path.join(stranger_dir, item)
            if os.path.isdir(item_path):
                for img_file in os.listdir(item_path):
                    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                        img_path = os.path.join(item_path, img_file)
                        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯è¯»
                        if os.path.exists(img_path) and os.path.isfile(img_path):
                            try:
                                img = cv2.imread(img_path)
                                if img is not None:
                                    stranger_count += 1
                            except:
                                print(f"   è·³è¿‡æ— æ³•è¯»å–çš„æ–‡ä»¶: {img_path}")
            elif item.lower().endswith(('.jpg', '.jpeg', '.png')):
                img_path = os.path.join(stranger_dir, item)
                if os.path.exists(img_path) and os.path.isfile(img_path):
                    try:
                        img = cv2.imread(img_path)
                        if img is not None:
                            stranger_count += 1
                    except:
                        print(f"   è·³è¿‡æ— æ³•è¯»å–çš„æ–‡ä»¶: {img_path}")

    print(f"   é™Œç”Ÿäººæ•°æ®: {stranger_count} å¼ å›¾ç‰‡")

    if user_count == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ç”¨æˆ·æ•°æ®")
        return False

    if stranger_count == 0:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°é™Œç”Ÿäººæ•°æ®ï¼Œæ¨¡å‹å°†åªèƒ½è¯†åˆ«ç”¨æˆ·")

    return True


def load_and_prepare_data():
    """åŠ è½½å¹¶å‡†å¤‡æ•°æ®"""
    print("\nğŸ“¥ åŠ è½½å’Œå‡†å¤‡æ•°æ®...")

    # åŠ è½½ç”¨æˆ·æ•°æ®
    user_imgs = []
    user_labels = []

    user_dir = './faces_user'
    for item in os.listdir(user_dir):
        item_path = os.path.join(user_dir, item)
        if os.path.isdir(item_path):
            for img_file in os.listdir(item_path):
                if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                    img_path = os.path.join(item_path, img_file)
                    if os.path.exists(img_path) and os.path.isfile(img_path):
                        try:
                            img = cv2.imread(img_path)
                            if img is not None:
                                # é¢„å¤„ç†
                                img = cv2.resize(img, (64, 64))
                                img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)
                                img_yuv[:, :, 0] = cv2.equalizeHist(img_yuv[:, :, 0])
                                img = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)

                                user_imgs.append(img)
                                user_labels.append([1.0, 0.0])  # ç”¨æˆ·æ ‡ç­¾
                        except:
                            print(f"   è·³è¿‡æ— æ³•è¯»å–çš„ç”¨æˆ·å›¾ç‰‡: {img_path}")

    print(f"   åŠ è½½ç”¨æˆ·å›¾ç‰‡: {len(user_imgs)} å¼ ")

    # åŠ è½½é™Œç”Ÿäººæ•°æ®
    stranger_imgs = []
    stranger_labels = []

    stranger_dir = './faces_strangers'
    if os.path.exists(stranger_dir):
        for item in os.listdir(stranger_dir):
            item_path = os.path.join(stranger_dir, item)
            if os.path.isdir(item_path):
                for img_file in os.listdir(item_path):
                    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                        img_path = os.path.join(item_path, img_file)
                        if os.path.exists(img_path) and os.path.isfile(img_path):
                            try:
                                img = cv2.imread(img_path)
                                if img is not None:
                                    # é¢„å¤„ç†
                                    img = cv2.resize(img, (64, 64))
                                    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)
                                    img_yuv[:, :, 0] = cv2.equalizeHist(img_yuv[:, :, 0])
                                    img = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)

                                    stranger_imgs.append(img)
                                    stranger_labels.append([0.0, 1.0])  # é™Œç”Ÿäººæ ‡ç­¾
                            except:
                                print(f"   è·³è¿‡æ— æ³•è¯»å–çš„é™Œç”Ÿäººå›¾ç‰‡: {img_path}")
            elif item.lower().endswith(('.jpg', '.jpeg', '.png')):
                img_path = os.path.join(stranger_dir, item)
                if os.path.exists(img_path) and os.path.isfile(img_path):
                    try:
                        img = cv2.imread(img_path)
                        if img is not None:
                            # é¢„å¤„ç†
                            img = cv2.resize(img, (64, 64))
                            img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)
                            img_yuv[:, :, 0] = cv2.equalizeHist(img_yuv[:, :, 0])
                            img = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)

                            stranger_imgs.append(img)
                            stranger_labels.append([0.0, 1.0])  # é™Œç”Ÿäººæ ‡ç­¾
                    except:
                        print(f"   è·³è¿‡æ— æ³•è¯»å–çš„é™Œç”Ÿäººå›¾ç‰‡: {img_path}")

    print(f"   åŠ è½½é™Œç”Ÿäººå›¾ç‰‡: {len(stranger_imgs)} å¼ ")

    # å¹³è¡¡æ•°æ® - å¦‚æœç”¨æˆ·æ•°æ®æ¯”é™Œç”Ÿäººå¤šï¼Œå¯¹é™Œç”Ÿäººè¿›è¡Œæ•°æ®å¢å¼º
    if len(stranger_imgs) < len(user_imgs) and len(stranger_imgs) > 0:
        print(f"   å¹³è¡¡æ•°æ®: é™Œç”Ÿäººæ•°æ®è¾ƒå°‘ï¼Œè¿›è¡Œæ•°æ®å¢å¼º")
        ratio = len(user_imgs) // len(stranger_imgs)
        if ratio > 1:
            additional_stranger_imgs = []
            additional_stranger_labels = []

            for _ in range(ratio - 1):
                for img, label in zip(stranger_imgs, stranger_labels):
                    # ç®€å•çš„æ•°æ®å¢å¼º
                    aug_img = cv2.flip(img, 1)  # æ°´å¹³ç¿»è½¬
                    additional_stranger_imgs.append(aug_img)
                    additional_stranger_labels.append(label)

            stranger_imgs.extend(additional_stranger_imgs)
            stranger_labels.extend(additional_stranger_labels)

    # åˆå¹¶æ•°æ®
    all_imgs = user_imgs + stranger_imgs
    all_labels = user_labels + stranger_labels

    print(f"   æ€»æ•°æ®: {len(all_imgs)} å¼ ")
    print(f"   ç”¨æˆ·æ ‡ç­¾: {sum(1 for label in all_labels if label[0] == 1.0)}")
    print(f"   é™Œç”Ÿäººæ ‡ç­¾: {sum(1 for label in all_labels if label[1] == 1.0)}")

    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    all_imgs = np.array(all_imgs, dtype=np.float32) / 255.0
    all_labels = np.array(all_labels, dtype=np.float32)

    # é‡å¡‘
    all_imgs = all_imgs.reshape(-1, 64, 64, 3)

    return all_imgs, all_labels


def train_fixed_model():
    """è®­ç»ƒä¿®å¤åçš„æ¨¡å‹"""
    print("\nğŸš€ å¼€å§‹è®­ç»ƒä¿®å¤æ¨¡å‹...")

    # éªŒè¯æ•°æ®
    if not verify_data():
        return False

    # åŠ è½½æ•°æ®
    all_imgs, all_labels = load_and_prepare_data()

    if len(all_imgs) == 0:
        print("âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•æ•°æ®")
        return False

    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    train_x, test_x, train_y, test_y = train_test_split(
        all_imgs, all_labels, test_size=0.2, random_state=42,
        stratify=np.argmax(all_labels, axis=1)
    )

    print(f"   è®­ç»ƒé›†: {len(train_x)} å¼ ")
    print(f"   æµ‹è¯•é›†: {len(test_x)} å¼ ")

    # æ„å»ºæ¨¡å‹
    print("\nğŸ§  æ„å»ºæ¨¡å‹...")

    # é‡ç½®è®¡ç®—å›¾
    tf.reset_default_graph()

    # å®šä¹‰å ä½ç¬¦
    input_image = tf.placeholder(tf.float32, [None, 64, 64, 3])
    input_label = tf.placeholder(tf.float32, [None, 2])  # 2ä¸ªç±»åˆ«
    dropout_rate = tf.placeholder(tf.float32)
    dropout_rate_2 = tf.placeholder(tf.float32)

    # æ„å»ºç½‘ç»œï¼ˆä½¿ç”¨ç®€å•çš„CNNç»“æ„ï¼‰
    conv1 = tf.layers.conv2d(input_image, 32, 3, activation=tf.nn.relu, padding='same')
    pool1 = tf.layers.max_pooling2d(conv1, 2, 2)

    conv2 = tf.layers.conv2d(pool1, 64, 3, activation=tf.nn.relu, padding='same')
    pool2 = tf.layers.max_pooling2d(conv2, 2, 2)

    conv3 = tf.layers.conv2d(pool2, 128, 3, activation=tf.nn.relu, padding='same')
    pool3 = tf.layers.max_pooling2d(conv3, 2, 2)

    flat = tf.layers.flatten(pool3)

    dense1 = tf.layers.dense(flat, 512, activation=tf.nn.relu)
    dropout1 = tf.nn.dropout(dense1, rate=1-dropout_rate)

    dense2 = tf.layers.dense(dropout1, 256, activation=tf.nn.relu)
    dropout2 = tf.nn.dropout(dense2, rate=1-dropout_rate_2)

    outdata = tf.layers.dense(dropout2, 2)  # 2ä¸ªè¾“å‡º

    # æŸå¤±å‡½æ•°
    cross_entropy = tf.reduce_mean(
        tf.nn.softmax_cross_entropy_with_logits(
            logits=outdata,
            labels=input_label
        )
    )

    # ä¼˜åŒ–å™¨
    optimizer = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)

    # å‡†ç¡®ç‡
    correct_prediction = tf.equal(tf.argmax(outdata, 1), tf.argmax(input_label, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

    # Saver
    saver = tf.train.Saver()

    # è®­ç»ƒ
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True

    with tf.Session(config=config) as sess:
        sess.run(tf.global_variables_initializer())

        print("\nğŸ“ˆ å¼€å§‹è®­ç»ƒ...")
        best_val_acc = 0
        patience_counter = 0
        patience = 10

        batch_size = 32
        num_epochs = 100

        for epoch in range(num_epochs):
            # æ‰“ä¹±è®­ç»ƒæ•°æ®
            indices = np.arange(len(train_x))
            np.random.shuffle(indices)
            train_x_shuffled = train_x[indices]
            train_y_shuffled = train_y[indices]

            # æ‰¹æ¬¡è®­ç»ƒ
            total_loss = 0
            num_batches = len(train_x_shuffled) // batch_size

            for i in range(num_batches):
                start_idx = i * batch_size
                end_idx = min((i + 1) * batch_size, len(train_x_shuffled))

                batch_x = train_x_shuffled[start_idx:end_idx]
                batch_y = train_y_shuffled[start_idx:end_idx]

                _, loss = sess.run([optimizer, cross_entropy],
                                  feed_dict={
                                      input_image: batch_x,
                                      input_label: batch_y,
                                      dropout_rate: 0.5,
                                      dropout_rate_2: 0.3
                                  })

                total_loss += loss

            avg_loss = total_loss / num_batches

            # éªŒè¯å‡†ç¡®ç‡
            val_acc = accuracy.eval(feed_dict={
                input_image: test_x,
                input_label: test_y,
                dropout_rate: 1.0,
                dropout_rate_2: 1.0
            })

            print(f"   è½®æ¬¡ {epoch+1:3d}/{num_epochs} - æŸå¤±: {avg_loss:.4f} - éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}")

            # æ£€æŸ¥å¼‚å¸¸å€¼
            if np.isnan(avg_loss) or np.isinf(avg_loss):
                print("   âŒ æ£€æµ‹åˆ°å¼‚å¸¸æŸå¤±å€¼ï¼Œåœæ­¢è®­ç»ƒ")
                break

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                saver.save(sess, './model_fixed/best_model')
                patience_counter = 0
                print(f"   âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (å‡†ç¡®ç‡: {val_acc:.4f})")
            else:
                patience_counter += 1

            # æ—©åœ
            if patience_counter >= patience:
                print(f"   ğŸ›‘ æ—©åœè§¦å‘ï¼Œè¿ç»­ {patience} è½®æœªæå‡")
                break

        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        saver.save(sess, './model_fixed/final_model')

        # ä¿å­˜ç±»åˆ«åç§°
        with open('./model_fixed/class_names.txt', 'w', encoding='utf-8') as f:
            f.write('ç”¨æˆ·\n')
            f.write('é™Œç”Ÿäºº\n')

        print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
        print(f"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")
        print(f"   æ¨¡å‹ä¿å­˜åˆ°: ./model_fixed/")

        return True


def test_model():
    """æµ‹è¯•ä¿®å¤åçš„æ¨¡å‹"""
    print("\nğŸ” æµ‹è¯•ä¿®å¤åçš„æ¨¡å‹...")

    import tensorflow.compat.v1 as tf
    tf.disable_v2_behavior()
    tf.disable_eager_execution()

    import numpy as np
    import cv2

    # åŠ è½½æ¨¡å‹
    try:
        # é‡ç½®å›¾
        tf.reset_default_graph()

        # å®šä¹‰ç½‘ç»œç»“æ„ï¼ˆä¸è®­ç»ƒæ—¶ç›¸åŒï¼‰
        input_image = tf.placeholder(tf.float32, [None, 64, 64, 3])
        dropout_rate = tf.placeholder(tf.float32)
        dropout_rate_2 = tf.placeholder(tf.float32)

        # é‡å»ºç½‘ç»œ
        conv1 = tf.layers.conv2d(input_image, 32, 3, activation=tf.nn.relu, padding='same')
        pool1 = tf.layers.max_pooling2d(conv1, 2, 2)

        conv2 = tf.layers.conv2d(pool1, 64, 3, activation=tf.nn.relu, padding='same')
        pool2 = tf.layers.max_pooling2d(conv2, 2, 2)

        conv3 = tf.layers.conv2d(pool2, 128, 3, activation=tf.nn.relu, padding='same')
        pool3 = tf.layers.max_pooling2d(conv3, 2, 2)

        flat = tf.layers.flatten(pool3)

        dense1 = tf.layers.dense(flat, 512, activation=tf.nn.relu)
        dropout1 = tf.nn.dropout(dense1, rate=1-dropout_rate)

        dense2 = tf.layers.dense(dropout1, 256, activation=tf.nn.relu)
        dropout2 = tf.nn.dropout(dense2, rate=1-dropout_rate_2)

        outdata = tf.layers.dense(dropout2, 2)

        saver = tf.train.Saver()

        with tf.Session() as sess:
            # æ¢å¤æ¨¡å‹
            saver.restore(sess, './model_fixed/best_model')
            print("   âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

            # æµ‹è¯•ä¸€äº›ç”¨æˆ·å›¾ç‰‡
            user_dir = './faces_user'
            for item in os.listdir(user_dir):
                item_path = os.path.join(user_dir, item)
                if os.path.isdir(item_path):
                    for img_file in os.listdir(item_path):
                        if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                            img_path = os.path.join(item_path, img_file)
                            if os.path.exists(img_path) and os.path.isfile(img_path):
                                try:
                                    img = cv2.imread(img_path)
                                    if img is not None:
                                        # é¢„å¤„ç†
                                        img = cv2.resize(img, (64, 64))
                                        img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)
                                        img_yuv[:, :, 0] = cv2.equalizeHist(img_yuv[:, :, 0])
                                        img = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)

                                        img_normalized = img.astype(np.float32) / 255.0
                                        img_batch = np.expand_dims(img_normalized, axis=0)

                                        # é¢„æµ‹
                                        logits = sess.run(outdata,
                                                        feed_dict={
                                                            input_image: img_batch,
                                                            dropout_rate: 1.0,
                                                            dropout_rate_2: 1.0
                                                        })

                                        # è®¡ç®—æ¦‚ç‡
                                        exp_logits = np.exp(logits - np.max(logits))
                                        probs = exp_logits / np.sum(exp_logits)

                                        print(f"   æµ‹è¯•å›¾ç‰‡: {img_file}")
                                        print(f"   åŸå§‹logits: {logits[0]}")
                                        print(f"   æ¦‚ç‡åˆ†å¸ƒ: ç”¨æˆ·={probs[0][0]:.4f}, é™Œç”Ÿäºº={probs[0][1]:.4f}")

                                        predicted_class = np.argmax(probs[0])
                                        class_names = ['ç”¨æˆ·', 'é™Œç”Ÿäºº']
                                        print(f"   é¢„æµ‹ç»“æœ: {class_names[predicted_class]}")
                                        print("   " + "-" * 40)

                                        # åªæµ‹è¯•ä¸€å¼ ç”¨æˆ·å›¾ç‰‡
                                        break
                                except:
                                    print(f"   è·³è¿‡æ— æ³•å¤„ç†çš„å›¾ç‰‡: {img_path}")
                    break

            return True

    except Exception as e:
        print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == '__main__':
    # é‡ç½®å¹¶è®­ç»ƒæ¨¡å‹
    success = reset_and_retrain()

    if success:
        print("\nğŸ‰ æ¨¡å‹é‡ç½®è®­ç»ƒæˆåŠŸ!")

        # æµ‹è¯•æ¨¡å‹
        test_model()

        print("\nâœ… ä¿®å¤å®Œæˆï¼è¯·ä½¿ç”¨æ–°çš„æ¨¡å‹ ./model_fixed/ è¿›è¡Œäººè„¸è¯†åˆ«")
    else:
        print("\nâŒ æ¨¡å‹é‡ç½®å¤±è´¥")



