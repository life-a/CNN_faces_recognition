"""---------------------------------------------------------
å››ã€äººè„¸è¯†åˆ« - å¤šç±»åˆ«äººè„¸è¯†åˆ«ç‰ˆæœ¬ï¼ˆä¿®å¤ç‰ˆ - å·²ä¿®æ­£å ä½ç¬¦é”™è¯¯ï¼‰
ä¿®å¤é—®é¢˜ï¼š
1. 'Placeholder_1' Graph execution error
2. æ€»æ˜¯è¯†åˆ«ä¸ºåŒä¸€ä¸ªäººçš„é—®é¢˜
3. æ·»åŠ æ—¶é—´å¹³æ»‘å’Œå†å²æŠ•ç¥¨
4. åŠ¨æ€ç½®ä¿¡åº¦é˜ˆå€¼
5. æ›´å¥½çš„è°ƒè¯•ä¿¡æ¯
------------------------------------------------------------"""
import tensorflow as tf
import cv2
import dlib
import numpy as np
import os
import sys
import time
from collections import deque, Counter

# ç¦ç”¨eager executionä»¥æ”¯æŒå ä½ç¬¦
tf.compat.v1.disable_eager_execution()

# å¯¼å…¥netæ¨¡å—
import net

class ImprovedFaceRecognizer:
    """æ”¹è¿›çš„äººè„¸è¯†åˆ«å™¨ï¼Œè§£å†³æ€»æ˜¯è¯†åˆ«ä¸ºåŒä¸€ä¸ªäººçš„é—®é¢˜"""

    def __init__(self, model_path='./model_balanced/'):
        self.model_path = model_path
        self.sess = None
        self.outdata = None
        self.input_image = None
        self.dropout_rate = None
        self.dropout_rate_2 = None
        self.class_names = []
        self.num_classes = 0

        # æ—¶é—´å¹³æ»‘å‚æ•°
        self.prediction_history = deque(maxlen=15)  # ä¿å­˜æœ€è¿‘15æ¬¡é¢„æµ‹
        self.confidence_history = deque(maxlen=15)   # ä¿å­˜æœ€è¿‘15æ¬¡ç½®ä¿¡åº¦

        # åŠ¨æ€é˜ˆå€¼å‚æ•°
        self.base_threshold = 0.65  # åŸºç¡€ç½®ä¿¡åº¦é˜ˆå€¼
        self.class_thresholds = {}   # æ¯ä¸ªç±»åˆ«çš„åŠ¨æ€é˜ˆå€¼

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_frames': 0,
            'faces_detected': 0,
            'predictions': [],
            'start_time': time.time()
        }

    def load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„å¹³è¡¡æ¨¡å‹"""
        print(f"ğŸ” æ­£åœ¨åŠ è½½æ¨¡å‹...")
        print(f"   æ¨¡å‹è·¯å¾„: {self.model_path}")

        # æ£€æŸ¥æ¨¡å‹ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.model_path):
            print(f"âŒ é”™è¯¯: æ¨¡å‹ç›®å½• {self.model_path} ä¸å­˜åœ¨")
            print(f"   è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ face_train_multi_person.py")
            return False

        # è¯»å–ç±»åˆ«åç§°
        class_names_file = os.path.join(self.model_path, 'class_names.txt')
        if not os.path.exists(class_names_file):
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°ç±»åˆ«åç§°æ–‡ä»¶ {class_names_file}")
            return False

        with open(class_names_file, 'r', encoding='utf-8') as f:
            self.class_names = [line.strip() for line in f.readlines() if line.strip()]

        self.num_classes = len(self.class_names)
        print(f"âœ… åŠ è½½äº† {self.num_classes} ä¸ªç±»åˆ«: {self.class_names}")

        # ä¸ºæ¯ä¸ªç±»åˆ«åˆå§‹åŒ–åŠ¨æ€é˜ˆå€¼
        for i, name in enumerate(self.class_names):
            if name == "é™Œç”Ÿäºº":
                self.class_thresholds[i] = 0.55  # é™Œç”Ÿäººé˜ˆå€¼è¾ƒä½
            else:
                self.class_thresholds[i] = 0.65  # å·²çŸ¥äººå‘˜é˜ˆå€¼è¾ƒé«˜

        # ğŸš¨ ä¿®å¤å…³é”®ï¼šæ­£ç¡®å®šä¹‰æ‰€æœ‰å ä½ç¬¦
        size = 64
        self.input_image = tf.compat.v1.placeholder(tf.float32, [None, size, size, 3], name='input_image')
        self.dropout_rate = tf.compat.v1.placeholder(tf.float32, name='dropout_rate')
        self.dropout_rate_2 = tf.compat.v1.placeholder(tf.float32, name='dropout_rate_2')

        # æ„å»ºç½‘ç»œ
        self.outdata = net.layer_net(self.input_image, self.num_classes,
                                     self.dropout_rate, self.dropout_rate_2)

        # åˆ›å»ºä¼šè¯
        config = tf.compat.v1.ConfigProto()
        config.gpu_options.allow_growth = True
        self.sess = tf.compat.v1.Session(config=config)

        saver = tf.compat.v1.train.Saver()

        # å°è¯•åŠ è½½æœ€ä½³æ¨¡å‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åŠ è½½æœ€ç»ˆæ¨¡å‹
        model_to_load = None
        best_model_path = os.path.join(self.model_path, 'best_model')
        final_model_path = os.path.join(self.model_path, 'final_model')

        if os.path.exists(best_model_path + '.index'):
            model_to_load = best_model_path
            print(f"   åŠ è½½æœ€ä½³æ¨¡å‹: {model_to_load}")
        elif os.path.exists(final_model_path + '.index'):
            model_to_load = final_model_path
            print(f"   åŠ è½½æœ€ç»ˆæ¨¡å‹: {model_to_load}")
        else:
            # å°è¯•æŸ¥æ‰¾ä»»ä½•checkpoint
            checkpoint = tf.train.latest_checkpoint(self.model_path)
            if checkpoint:
                model_to_load = checkpoint
                print(f"   åŠ è½½æœ€æ–°æ¨¡å‹: {model_to_load}")
            else:
                print(f"âŒ é”™è¯¯: åœ¨ {self.model_path} ä¸­æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶")
                return False

        try:
            saver.restore(self.sess, model_to_load)
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

            # æµ‹è¯•æ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
            test_input = np.random.randn(1, 64, 64, 3) * 0.1
            probs = self.sess.run(tf.nn.softmax(self.outdata),
                                 feed_dict={
                                     self.input_image: test_input,
                                     self.dropout_rate: 1.0,  # ğŸš¨ ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å ä½ç¬¦å˜é‡
                                     self.dropout_rate_2: 1.0  # ğŸš¨ ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å ä½ç¬¦å˜é‡
                                 })
            print(f"   æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼Œè¾“å‡ºshape: {probs.shape}")
            return True

        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def preprocess_face(self, face_img):
        """é¢„å¤„ç†äººè„¸å›¾åƒ"""
        if face_img is None or face_img.size == 0:
            return None

        # è°ƒæ•´å¤§å°åˆ°64x64
        face_resized = cv2.resize(face_img, (64, 64))

        # ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼ˆå¢å¼ºå¯¹æ¯”åº¦ï¼‰
        img_yuv = cv2.cvtColor(face_resized, cv2.COLOR_BGR2YUV)
        img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])
        face_eq = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)

        # è½»å¾®é«˜æ–¯æ¨¡ç³Šå»å™ª
        face_blur = cv2.GaussianBlur(face_eq, (3, 3), 0)

        return face_blur

    def recognize_single_frame(self, face_img):
        """è¯†åˆ«å•å¸§ä¸­çš„äººè„¸"""
        if face_img is None:
            return None, 0.0, None

        # é¢„å¤„ç†
        processed_face = self.preprocess_face(face_img)
        if processed_face is None:
            return None, 0.0, None

        # å½’ä¸€åŒ–
        face_normalized = processed_face.astype(np.float32) / 255.0

        try:
            # ğŸš¨ ä¿®å¤å…³é”®ï¼šæ­£ç¡®ä¼ é€’æ‰€æœ‰å ä½ç¬¦
            logits = self.sess.run(self.outdata,
                                  feed_dict={
                                      self.input_image: [face_normalized],
                                      self.dropout_rate: 1.0,  # æ¨ç†æ—¶dropoutç‡ä¸º1.0ï¼ˆä¸ä½¿ç”¨dropoutï¼‰
                                      self.dropout_rate_2: 1.0  # æ¨ç†æ—¶dropoutç‡ä¸º1.0ï¼ˆä¸ä½¿ç”¨dropoutï¼‰
                                  })

            # è®¡ç®—softmaxæ¦‚ç‡
            exp_logits = np.exp(logits - np.max(logits))
            probs = exp_logits / np.sum(exp_logits)
            probs = probs[0]  # å–ç¬¬ä¸€ä¸ªæ ·æœ¬

            # è·å–åŸå§‹é¢„æµ‹ç»“æœ
            raw_predicted = np.argmax(probs)
            raw_confidence = np.max(probs)

            return raw_predicted, raw_confidence, probs

        except Exception as e:
            print(f"âš ï¸ æ¨¡å‹æ¨ç†é”™è¯¯: {e}")
            return None, 0.0, None

    def recognize_with_smoothing(self, face_img):
        """ä½¿ç”¨æ—¶é—´å¹³æ»‘çš„è¯†åˆ«äººè„¸"""
        # è·å–å½“å‰å¸§çš„è¯†åˆ«ç»“æœ
        raw_predicted, raw_confidence, probs = self.recognize_single_frame(face_img)

        if raw_predicted is None:
            return None, 0.0, None

        # ä¿å­˜åˆ°å†å²
        self.prediction_history.append(raw_predicted)
        self.confidence_history.append(raw_confidence)

        # åº”ç”¨æ—¶é—´å¹³æ»‘ï¼šä½¿ç”¨å†å²æŠ•ç¥¨
        final_predicted = raw_predicted
        final_confidence = raw_confidence

        if len(self.prediction_history) >= 5:
            # è®¡ç®—æœ€è¿‘5æ¬¡é¢„æµ‹çš„ä¼—æ•°
            recent_predictions = list(self.prediction_history)[-5:]
            pred_counter = Counter(recent_predictions)
            most_common_pred, most_common_count = pred_counter.most_common(1)[0]

            # å¦‚æœä¼—æ•°å‡ºç°æ¬¡æ•°è¶…è¿‡3æ¬¡ï¼Œä¸”ä¸å½“å‰é¢„æµ‹ä¸åŒ
            if most_common_count >= 3 and most_common_pred != raw_predicted:
                final_predicted = most_common_pred
                # è®¡ç®—è¯¥ç±»åˆ«åœ¨å†å²ä¸­çš„å¹³å‡ç½®ä¿¡åº¦
                confidences = [conf for pred, conf in
                              zip(list(self.prediction_history), list(self.confidence_history))
                              if pred == most_common_pred]
                final_confidence = np.mean(confidences) if confidences else raw_confidence

        # åº”ç”¨åŠ¨æ€é˜ˆå€¼
        class_threshold = self.class_thresholds.get(final_predicted, self.base_threshold)

        # å¦‚æœç½®ä¿¡åº¦ä½äºç±»åˆ«é˜ˆå€¼ï¼Œåˆ™è®¤ä¸ºæ˜¯é™Œç”Ÿäºº
        if final_confidence < class_threshold:
            # æ‰¾åˆ°é™Œç”Ÿäººå¯¹åº”çš„ç±»åˆ«ç´¢å¼•
            stranger_idx = None
            for i, name in enumerate(self.class_names):
                if name == "é™Œç”Ÿäºº":
                    stranger_idx = i
                    break

            if stranger_idx is not None:
                final_predicted = stranger_idx
                final_confidence = probs[stranger_idx] if probs is not None else 0.0

        return final_predicted, final_confidence, probs

    def get_class_color(self, class_idx, confidence):
        """æ ¹æ®ç±»åˆ«å’Œç½®ä¿¡åº¦è·å–æ˜¾ç¤ºé¢œè‰²"""
        if class_idx >= len(self.class_names):
            return (128, 128, 128)  # ç°è‰² - æœªçŸ¥ç±»åˆ«

        class_name = self.class_names[class_idx]

        if class_name == "é™Œç”Ÿäºº":
            if confidence > 0.7:
                return (0, 0, 255)  # çº¢è‰² - é«˜ç½®ä¿¡åº¦é™Œç”Ÿäºº
            else:
                return (0, 165, 255)  # æ©™è‰² - ä½ç½®ä¿¡åº¦é™Œç”Ÿäºº
        else:
            if confidence > 0.75:
                return (0, 255, 0)  # ç»¿è‰² - é«˜ç½®ä¿¡åº¦å·²çŸ¥äººå‘˜
            elif confidence > 0.6:
                return (255, 255, 0)  # é»„è‰² - ä¸­ç­‰ç½®ä¿¡åº¦
            else:
                return (255, 165, 0)  # æ©™è‰² - ä½ç½®ä¿¡åº¦

    def close(self):
        """å…³é—­èµ„æº"""
        if self.sess:
            self.sess.close()

    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        total_time = time.time() - self.stats['start_time']

        print(f"\nğŸ“ˆ è¯†åˆ«ç»Ÿè®¡:")
        print(f"   æ€»å¸§æ•°: {self.stats['total_frames']}")
        print(f"   æ£€æµ‹åˆ°äººè„¸: {self.stats['faces_detected']} æ¬¡")
        print(f"   è¿è¡Œæ—¶é—´: {total_time:.2f}ç§’")

        if self.stats['total_frames'] > 0:
            fps = self.stats['total_frames'] / total_time
            print(f"   å¹³å‡å¸§ç‡: {fps:.2f} FPS")

        if self.stats['predictions']:
            pred_counter = Counter(self.stats['predictions'])
            print(f"\nğŸ“Š é¢„æµ‹åˆ†å¸ƒ:")
            for i in range(self.num_classes):
                class_name = self.class_names[i] if i < len(self.class_names) else f"Class_{i}"
                count = pred_counter.get(i, 0)
                percentage = count / len(self.stats['predictions']) * 100
                print(f"   {class_name}: {count}æ¬¡ ({percentage:.1f}%)")

def main():
    """ä¸»å‡½æ•°"""

    print("=" * 60)
    print("          æ”¹è¿›ç‰ˆå¤šç±»åˆ«äººè„¸è¯†åˆ«ç³»ç»Ÿ (å·²ä¿®å¤)")
    print("=" * 60)

    # åˆ›å»ºè¯†åˆ«å™¨å®ä¾‹ - å…ˆå°è¯•æ–°çš„å¹³è¡¡æ¨¡å‹
    recognizer = ImprovedFaceRecognizer(model_path='./model_balanced/')

    # åŠ è½½æ¨¡å‹
    if not recognizer.load_model():
        print("å°è¯•åŠ è½½åŸå§‹æ¨¡å‹...")
        recognizer = ImprovedFaceRecognizer(model_path='./model_multi_class/')
        if not recognizer.load_model():
            print("âŒ æ— æ³•åŠ è½½ä»»ä½•æ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
            print("è¿è¡Œå‘½ä»¤: python face_train_multi_person.py")
            return

    # åˆå§‹åŒ–äººè„¸æ£€æµ‹å™¨
    detector = dlib.get_frontal_face_detector()

    # æ‰“å¼€æ‘„åƒå¤´
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        recognizer.close()
        return

    print(f"\nğŸš€ äººè„¸è¯†åˆ«ç³»ç»Ÿå·²å¯åŠ¨")
    print("   æŒ‰ä»¥ä¸‹é”®æ“ä½œ:")
    print("   ESC  : é€€å‡ºç¨‹åº")
    print("   V    : åˆ‡æ¢è¯¦ç»†æ¨¡å¼")
    print("   R    : é‡ç½®è¯†åˆ«å†å²")
    print("   +    : æé«˜ç½®ä¿¡åº¦é˜ˆå€¼")
    print("   -    : é™ä½ç½®ä¿¡åº¦é˜ˆå€¼")
    print("   S    : æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯")
    print("   C    : æ¸…é™¤å±å¹•è¾“å‡º")
    print(f"\nğŸ“Š å½“å‰è®¾ç½®:")
    print(f"   åŸºç¡€é˜ˆå€¼: {recognizer.base_threshold:.2f}")
    print(f"   ç±»åˆ«æ•°: {recognizer.num_classes}")

    # æ§åˆ¶å˜é‡
    show_details = False
    clear_console = False

    # æ€§èƒ½ç›‘æ§
    fps_counter = deque(maxlen=30)
    last_time = time.time()
    last_print_time = time.time()

    while True:
        # è¯»å–å¸§
        ret, frame = cap.read()
        if not ret:
            print("âŒ æ— æ³•ä»æ‘„åƒå¤´è¯»å–å¸§")
            break

        recognizer.stats['total_frames'] += 1

        # è®¡ç®—FPS
        current_time = time.time()
        fps = 1.0 / (current_time - last_time) if current_time != last_time else 0
        fps_counter.append(fps)
        avg_fps = np.mean(fps_counter) if fps_counter else 0
        last_time = current_time

        # é•œåƒæ˜¾ç¤ºï¼ˆæ›´è‡ªç„¶ï¼‰
        frame = cv2.flip(frame, 1)

        # è½¬æ¢ä¸ºç°åº¦å›¾è¿›è¡Œäººè„¸æ£€æµ‹
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # äººè„¸æ£€æµ‹
        faces = detector(gray, 1)

        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°äººè„¸
        if len(faces) == 0:
            cv2.putText(frame, "No face detected", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        else:
            recognizer.stats['faces_detected'] += len(faces)

        # å¤„ç†æ¯ä¸ªæ£€æµ‹åˆ°çš„äººè„¸
        for i, face in enumerate(faces):
            try:
                # è·å–äººè„¸è¾¹ç•Œæ¡†
                x1 = max(face.top(), 0)
                y1 = min(face.bottom(), frame.shape[0])
                x2 = max(face.left(), 0)
                y2 = min(face.right(), frame.shape[1])

                # æå–äººè„¸åŒºåŸŸ
                face_img = frame[x1:y1, x2:y2]
                if face_img.size == 0:
                    continue

                # è¯†åˆ«äººè„¸ï¼ˆä½¿ç”¨æ—¶é—´å¹³æ»‘ï¼‰
                predicted_class, confidence, all_probs = recognizer.recognize_with_smoothing(face_img)

                if predicted_class is None:
                    continue

                # ä¿å­˜åˆ°ç»Ÿè®¡
                recognizer.stats['predictions'].append(predicted_class)

                # è·å–ç±»åˆ«åç§°
                if predicted_class < len(recognizer.class_names):
                    person_name = recognizer.class_names[predicted_class]
                else:
                    person_name = "æœªçŸ¥"

                # è·å–æ˜¾ç¤ºé¢œè‰²
                color = recognizer.get_class_color(predicted_class, confidence)

                # å‡†å¤‡æ˜¾ç¤ºæ–‡æœ¬
                if person_name == "é™Œç”Ÿäºº":
                    display_text = f"Stranger ({confidence:.2f})"
                else:
                    display_text = f"{person_name} ({confidence:.2f})"

                # ç»˜åˆ¶äººè„¸è¾¹ç•Œæ¡†
                cv2.rectangle(frame, (x2, x1), (y2, y1), color, 2)

                # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
                text_size = cv2.getTextSize(display_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                cv2.rectangle(frame,
                            (x2, x1 - text_size[1] - 10),
                            (x2 + text_size[0], x1),
                            color, -1)

                # ç»˜åˆ¶æ–‡æœ¬
                cv2.putText(frame, display_text,
                          (x2, x1 - 5),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.6,
                          (255, 255, 255), 2)

                # åœ¨å³ä¸Šè§’æ˜¾ç¤ºè¯¦ç»†æ¦‚ç‡ï¼ˆå¦‚æœå¼€å¯è¯¦ç»†æ¨¡å¼ï¼‰
                if show_details and i == 0 and all_probs is not None:  # åªæ˜¾ç¤ºç¬¬ä¸€ä¸ªè„¸çš„è¯¦ç»†æ¦‚ç‡
                    prob_text_y = 30

                    # æ˜¾ç¤ºå‰3ä¸ªæ¦‚ç‡
                    top_indices = np.argsort(all_probs)[-3:][::-1]
                    for idx in top_indices:
                        if idx < len(recognizer.class_names):
                            class_name = recognizer.class_names[idx]
                            prob = all_probs[idx]

                            prob_text = f"{class_name}: {prob:.3f}"
                            text_width = frame.shape[1] - 200

                            cv2.putText(frame, prob_text,
                                      (text_width, prob_text_y),
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                                      (255, 255, 255), 1)
                            prob_text_y += 20

                # å®šæœŸè¾“å‡ºè¯†åˆ«ç»“æœåˆ°æ§åˆ¶å°ï¼ˆæ¯2ç§’ä¸€æ¬¡ï¼‰
                if current_time - last_print_time > 2.0 and i == 0:
                    if clear_console:
                        os.system('cls' if os.name == 'nt' else 'clear')
                        clear_console = False

                    print(f"[{time.strftime('%H:%M:%S')}] è¯†åˆ«: {person_name}, ç½®ä¿¡åº¦: {confidence:.4f}")
                    last_print_time = current_time

            except Exception as e:
                print(f"âš ï¸ å¤„ç†äººè„¸æ—¶å‡ºé”™: {e}")
                continue

        # æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯
        info_y = 30

        # æ˜¾ç¤ºFPS
        fps_text = f"FPS: {avg_fps:.1f}"
        cv2.putText(frame, fps_text, (10, info_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        info_y += 30

        # æ˜¾ç¤ºå¸§æ•°
        frame_text = f"Frame: {recognizer.stats['total_frames']}"
        cv2.putText(frame, frame_text, (10, info_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        info_y += 30

        # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„äººè„¸æ•°
        faces_text = f"Faces: {len(faces)}"
        cv2.putText(frame, faces_text, (10, info_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 200, 0), 2)
        info_y += 30

        # æ˜¾ç¤ºå†å²é•¿åº¦
        history_text = f"History: {len(recognizer.prediction_history)}"
        cv2.putText(frame, history_text, (10, info_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 255), 2)

        # æ˜¾ç¤ºå½“å‰é˜ˆå€¼
        threshold_text = f"Threshold: {recognizer.base_threshold:.2f}"
        cv2.putText(frame, threshold_text, (frame.shape[1] - 200, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

        # æ˜¾ç¤ºæ¨¡å¼çŠ¶æ€
        if show_details:
            cv2.putText(frame, "DETAIL MODE", (frame.shape[1] - 200, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

        # æ˜¾ç¤ºæ“ä½œæç¤º
        cv2.putText(frame, "ESC:quit, V:details, R:reset, +/-:threshold",
                   (10, frame.shape[0] - 10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)

        # æ˜¾ç¤ºçª—å£
        window_title = "Fixed Face Recognition - Press ESC to quit"
        cv2.imshow(window_title, frame)

        # å¤„ç†æŒ‰é”®è¾“å…¥
        key = cv2.waitKey(1) & 0xFF

        if key == 27:  # ESCé”®
            break
        elif key == ord('v') or key == ord('V'):  # åˆ‡æ¢è¯¦ç»†æ¨¡å¼
            show_details = not show_details
            print(f"è¯¦ç»†æ¨¡å¼: {'å¼€å¯' if show_details else 'å…³é—­'}")
        elif key == ord('r') or key == ord('R'):  # é‡ç½®å†å²
            recognizer.prediction_history.clear()
            recognizer.confidence_history.clear()
            print("è¯†åˆ«å†å²å·²é‡ç½®")
        elif key == ord('+'):  # æé«˜é˜ˆå€¼
            recognizer.base_threshold = min(0.9, recognizer.base_threshold + 0.05)
            for i in recognizer.class_thresholds:
                recognizer.class_thresholds[i] = min(0.9, recognizer.class_thresholds[i] + 0.05)
            print(f"ç½®ä¿¡åº¦é˜ˆå€¼æé«˜åˆ°: {recognizer.base_threshold:.2f}")
        elif key == ord('-'):  # é™ä½é˜ˆå€¼
            recognizer.base_threshold = max(0.3, recognizer.base_threshold - 0.05)
            for i in recognizer.class_thresholds:
                recognizer.class_thresholds[i] = max(0.3, recognizer.class_thresholds[i] - 0.05)
            print(f"ç½®ä¿¡åº¦é˜ˆå€¼é™ä½åˆ°: {recognizer.base_threshold:.2f}")
        elif key == ord('s') or key == ord('S'):  # æ˜¾ç¤ºç»Ÿè®¡
            recognizer.print_stats()
        elif key == ord('c') or key == ord('C'):  # æ¸…é™¤æ§åˆ¶å°
            clear_console = True
            os.system('cls' if os.name == 'nt' else 'clear')

    # é‡Šæ”¾èµ„æº
    cap.release()
    cv2.destroyAllWindows()
    recognizer.close()

    # æ‰“å°æœ€ç»ˆç»Ÿè®¡
    print(f"\n{'='*60}")
    print("          è¯†åˆ«ç³»ç»Ÿå·²å…³é—­")
    print(f"{'='*60}")
    recognizer.print_stats()
    print(f"{'='*60}")

if __name__ == '__main__':
    main()