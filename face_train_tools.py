"""
faces_train_multi_person.py - äººè„¸è¯†åˆ«æ¨¡å‹è®­ç»ƒå·¥å…·ç±»
é‡æ„ä¸ºå¯è°ƒç”¨çš„æ¨¡å—ï¼Œæ”¯æŒå¤šç±»åˆ«äººè„¸è¯†åˆ«è®­ç»ƒ
"""

import cv2
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
import shutil
import random
import os
import time
import matplotlib.pyplot as plt
import sys
import threading

# å¯ç”¨v1å…¼å®¹æ¨¡å¼
tf.compat.v1.disable_eager_execution()


def layer_net_tf1(input_image, num_class, dropout_rate, dropout_rate_2):
    """
    TensorFlow 1.x ç‰ˆæœ¬çš„layer_netå‡½æ•°
    ä¸ä¸»çª—å£ä¸­çš„layer_netå‡½æ•°ä¿æŒä¸€è‡´
    """
    """ç¬¬ä¸€ã€äºŒå±‚ï¼Œè¾“å…¥å›¾ç‰‡64*64*3ï¼Œè¾“å‡ºå›¾ç‰‡32*32*32"""
    w1 = tf.Variable(tf.random.normal([3, 3, 3, 32]), name='w1')  # å·ç§¯æ ¸å¤§å°(3,3)ï¼Œ è¾“å…¥é€šé“(3)ï¼Œ è¾“å‡ºé€šé“(32)
    b1 = tf.Variable(tf.random.normal([32]), name='b1')
    layer_conv1 = tf.nn.relu(
        tf.nn.conv2d(input_image, w1, strides=[1, 1, 1, 1], padding='SAME') + b1)  # 64*64*32ï¼Œå·ç§¯æå–ç‰¹å¾ï¼Œå¢åŠ é€šé“æ•°
    layer_pool1 = tf.nn.max_pool2d(layer_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],
                                   padding='SAME')  # 32*32*32ï¼Œæ± åŒ–é™ç»´ï¼Œå‡å°å¤æ‚åº¦
    drop1 = tf.nn.dropout(layer_pool1, rate=1 - dropout_rate)  # æŒ‰ä¸€å®šæ¦‚ç‡éšæœºä¸¢å¼ƒä¸€äº›ç¥ç»å…ƒï¼Œä»¥è·å¾—æ›´é«˜çš„è®­ç»ƒé€Ÿåº¦ä»¥åŠé˜²æ­¢è¿‡æ‹Ÿåˆ

    """ç¬¬ä¸‰ã€å››å±‚ï¼Œè¾“å…¥å›¾ç‰‡32*32*32ï¼Œè¾“å‡ºå›¾ç‰‡16*16*64"""
    w2 = tf.Variable(tf.random.normal([3, 3, 32, 64]), name='w2')  # å·ç§¯æ ¸å¤§å°(3,3)ï¼Œ è¾“å…¥é€šé“(32)ï¼Œ è¾“å‡ºé€šé“(64)
    b2 = tf.Variable(tf.random.normal([64]), name='b2')
    layer_conv2 = tf.nn.relu(tf.nn.conv2d(drop1, w2, strides=[1, 1, 1, 1], padding='SAME') + b2)  # 32*32*64
    layer_pool2 = tf.nn.max_pool2d(layer_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')  # 16*16*64
    drop2 = tf.nn.dropout(layer_pool2, rate=1 - dropout_rate)

    """ç¬¬äº”ã€å…­å±‚ï¼Œè¾“å…¥å›¾ç‰‡16*16*64ï¼Œè¾“å‡ºå›¾ç‰‡8*8*64"""
    w3 = tf.Variable(tf.random.normal([3, 3, 64, 64]), name='w3')  # å·ç§¯æ ¸å¤§å°(3,3)ï¼Œ è¾“å…¥é€šé“(64)ï¼Œ è¾“å‡ºé€šé“(64)
    b3 = tf.Variable(tf.random.normal([64]), name='b3')
    layer_conv3 = tf.nn.relu(tf.nn.conv2d(drop2, w3, strides=[1, 1, 1, 1], padding='SAME') + b3)  # 16*16*64
    layer_pool3 = tf.nn.max_pool2d(layer_conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],
                                   padding='SAME')  # 8*8*64=4096
    drop3 = tf.nn.dropout(layer_pool3, rate=1 - dropout_rate)

    """ç¬¬ä¸ƒå±‚ï¼Œå…¨è¿æ¥å±‚ï¼Œå°†å›¾ç‰‡çš„å·ç§¯è¾“å‡ºå‹æ‰æˆä¸€ä¸ªä¸€ç»´å‘é‡ï¼Œè¾“å…¥å›¾ç‰‡8*8*64ï¼Œreshapeåˆ°1*4096ï¼Œè¾“å‡º1*512"""
    w4 = tf.Variable(tf.random.normal([8 * 8 * 64, 512]), name='w4')  # è¾“å…¥é€šé“(4096)ï¼Œ è¾“å‡ºé€šé“(512)
    b4 = tf.Variable(tf.random.normal([512]), name='b4')
    layer_fully_connected = tf.reshape(drop3, [-1, 8 * 8 * 64])  # -1è¡¨ç¤ºè¡Œéšç€åˆ—çš„éœ€æ±‚æ”¹å˜ï¼Œ1*4096
    relu = tf.nn.relu(tf.matmul(layer_fully_connected, w4) + b4)  # [1,4096]*[4096,512]=[1,512]
    drop4 = tf.nn.dropout(relu, rate=1 - dropout_rate_2)

    """ç¬¬å…«å±‚ï¼Œè¾“å‡ºå±‚ï¼Œè¾“å…¥1*512ï¼Œè¾“å‡º1*num_class"""
    w5 = tf.Variable(tf.random.normal([512, num_class]), name='w5')  # è¾“å…¥é€šé“(512)ï¼Œ è¾“å‡ºé€šé“(num_class)
    b5 = tf.Variable(tf.random.normal([num_class]), name='b5')
    outdata = tf.add(tf.matmul(drop4, w5), b5)  # (1,512)*(512,num_class)=(1,num_class)

    return outdata


class BalancedDataLoader:
    """å¹³è¡¡æ•°æ®åŠ è½½å™¨ï¼Œè§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜"""

    def __init__(self, target_samples_per_class=500):
        self.target_samples = target_samples_per_class
        self.augmentation_techniques = [
            self.horizontal_flip,
            self.adjust_brightness,
            self.adjust_contrast,
            self.random_rotation,
            self.add_noise
        ]

    def horizontal_flip(self, img):
        """æ°´å¹³ç¿»è½¬"""
        return cv2.flip(img, 1)

    def adjust_brightness(self, img):
        """è°ƒæ•´äº®åº¦"""
        alpha = random.uniform(0.7, 1.3)
        beta = random.randint(-30, 30)
        return cv2.convertScaleAbs(img, alpha=alpha, beta=beta)

    def adjust_contrast(self, img):
        """è°ƒæ•´å¯¹æ¯”åº¦"""
        alpha = random.uniform(0.8, 1.2)
        return cv2.convertScaleAbs(img, alpha=alpha, beta=0)

    def random_rotation(self, img):
        """éšæœºå°è§’åº¦æ—‹è½¬"""
        angle = random.uniform(-15, 15)
        h, w = img.shape[:2]
        center = (w // 2, h // 2)
        M = cv2.getRotationMatrix2D(center, angle, 1.0)
        return cv2.warpAffine(img, M, (w, h), borderMode=cv2.BORDER_REPLICATE)

    def add_noise(self, img):
        """æ·»åŠ é«˜æ–¯å™ªå£°"""
        noise = np.random.normal(0, 5, img.shape).astype(np.uint8)
        noisy_img = cv2.add(img, noise)
        return np.clip(noisy_img, 0, 255)

    def augment_image(self, img, num_augment=3):
        """å¢å¼ºå•å¼ å›¾ç‰‡"""
        augmented = [img]
        for _ in range(num_augment):
            # éšæœºé€‰æ‹©å¢å¼ºæŠ€æœ¯
            technique = random.choice(self.augmentation_techniques)
            try:
                aug_img = technique(img.copy())
                augmented.append(aug_img)
            except:
                # å¦‚æœå¢å¼ºå¤±è´¥ï¼Œä½¿ç”¨åŸå›¾
                augmented.append(img.copy())
        return augmented

    def load_balanced_data(self, faces_ok_dir, faces_no_dir, size=64):
        """åŠ è½½å¹¶å¹³è¡¡æ•°æ®"""
        imgs = []
        labs = []
        class_names = []

        # è·å–faces_okä¸‹çš„æ‰€æœ‰äººå‘˜ç›®å½•
        person_dirs = []
        for item in os.listdir(faces_ok_dir):
            item_path = os.path.join(faces_ok_dir, item)
            if os.path.isdir(item_path):
                person_dirs.append((item, item_path))
                class_names.append(item)

        if not person_dirs:
            print(f"é”™è¯¯: {faces_ok_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°äººå‘˜ç›®å½•")
            return None, None, None

        # æ·»åŠ é™Œç”Ÿäººç±»åˆ«
        class_names.append("é™Œç”Ÿäºº")
        num_classes = len(class_names)

        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   å·²çŸ¥äººå‘˜: {len(person_dirs)} äºº")
        print(f"   æ€»ç±»åˆ«æ•°: {num_classes}")

        # ç¬¬ä¸€æ­¥ï¼šç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„åŸå§‹å›¾ç‰‡æ•°é‡
        class_counts = {}
        for person_name, person_path in person_dirs:
            files = [f for f in os.listdir(person_path)
                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
            class_counts[person_name] = len(files)
            print(f"   {person_name}: {len(files)} å¼ åŸå§‹å›¾ç‰‡")

        # ç»Ÿè®¡é™Œç”Ÿäººå›¾ç‰‡æ•°é‡
        stranger_files = []
        if os.path.exists(faces_no_dir):
            stranger_files = [f for f in os.listdir(faces_no_dir)
                              if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        class_counts["é™Œç”Ÿäºº"] = len(stranger_files)
        print(f"   é™Œç”Ÿäºº: {len(stranger_files)} å¼ åŸå§‹å›¾ç‰‡")

        # ç¬¬äºŒæ­¥ï¼šç¡®å®šæ¯ä¸ªç±»åˆ«çš„ç›®æ ‡æ ·æœ¬æ•°
        # ä½¿ç”¨æœ€å°ç±»åˆ«çš„2å€ä½œä¸ºä¸Šé™ï¼Œç¡®ä¿å¹³è¡¡
        min_count = min(class_counts.values())
        target_per_class = min(self.target_samples, min_count * 2)
        print(f"\nâš–ï¸ å¹³è¡¡ç­–ç•¥:")
        print(f"   æœ€å°ç±»åˆ«æ ·æœ¬æ•°: {min_count}")
        print(f"   æ¯ç±»ç›®æ ‡æ ·æœ¬æ•°: {target_per_class}")

        # ç¬¬ä¸‰æ­¥ï¼šåŠ è½½å¹¶å¹³è¡¡å·²çŸ¥äººå‘˜æ•°æ®
        for idx, (person_name, person_path) in enumerate(person_dirs):
            print(f"\nğŸ“¥ åŠ è½½ {person_name} çš„æ•°æ®...")

            # è·å–è¯¥äººå‘˜çš„æ‰€æœ‰å›¾ç‰‡
            files = [f for f in os.listdir(person_path)
                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

            # å¦‚æœå›¾ç‰‡å¤ªå¤šï¼Œéšæœºé€‰æ‹©ä¸€éƒ¨åˆ†
            if len(files) > target_per_class:
                files = random.sample(files, target_per_class)

            loaded = 0
            need_augment = target_per_class - len(files)

            for file_idx, filename in enumerate(files):
                img_path = os.path.join(person_path, filename)
                img = cv2.imread(img_path)

                if img is not None:
                    # ç»Ÿä¸€å°ºå¯¸
                    img_resized = cv2.resize(img, (size, size))

                    # æ·»åŠ åŸå§‹å›¾ç‰‡
                    imgs.append(img_resized)

                    # åˆ›å»ºone-hotæ ‡ç­¾
                    label = [0] * num_classes
                    label[idx] = 1
                    labs.append(label)
                    loaded += 1

                    # å¦‚æœéœ€è¦å¢å¼ºä¸”æ˜¯å‰å‡ ä¸ªæ ·æœ¬
                    if need_augment > 0 and file_idx < min(20, len(files)):
                        # ä¸ºæ¯ä¸ªåŸå§‹å›¾ç‰‡åˆ›å»º2ä¸ªå¢å¼ºç‰ˆæœ¬
                        augmented_imgs = self.augment_image(img_resized, num_augment=2)
                        for aug_img in augmented_imgs[1:]:  # è·³è¿‡åŸå§‹å›¾ç‰‡
                            imgs.append(aug_img)
                            labs.append(label.copy())
                            loaded += 1
                            need_augment -= 1
                            if need_augment <= 0:
                                break

                if loaded >= target_per_class:
                    break

            print(f"   âœ… åŠ è½½å®Œæˆ: {loaded} å¼ å›¾ç‰‡")

        # ç¬¬å››æ­¥ï¼šåŠ è½½å¹¶å¹³è¡¡é™Œç”Ÿäººæ•°æ®
        print(f"\nğŸ“¥ åŠ è½½é™Œç”Ÿäººæ•°æ®...")
        if os.path.exists(faces_no_dir) and stranger_files:
            # å¦‚æœé™Œç”Ÿäººå›¾ç‰‡å¤ªå¤šï¼Œéšæœºé€‰æ‹©
            if len(stranger_files) > target_per_class:
                selected_files = random.sample(stranger_files, target_per_class)
            else:
                selected_files = stranger_files

            loaded = 0
            need_augment = target_per_class - len(selected_files)

            for file_idx, filename in enumerate(selected_files):
                img_path = os.path.join(faces_no_dir, filename)
                img = cv2.imread(img_path)

                if img is not None:
                    # ç»Ÿä¸€å°ºå¯¸
                    img_resized = cv2.resize(img, (size, size))

                    # æ·»åŠ åŸå§‹å›¾ç‰‡
                    imgs.append(img_resized)

                    # åˆ›å»ºone-hotæ ‡ç­¾ï¼ˆæœ€åä¸€ä¸ªç±»åˆ«ï¼‰
                    label = [0] * num_classes
                    label[-1] = 1
                    labs.append(label)
                    loaded += 1

                    # å¦‚æœéœ€è¦å¢å¼º
                    if need_augment > 0 and file_idx < min(20, len(selected_files)):
                        augmented_imgs = self.augment_image(img_resized, num_augment=2)
                        for aug_img in augmented_imgs[1:]:
                            imgs.append(aug_img)
                            labs.append(label.copy())
                            loaded += 1
                            need_augment -= 1
                            if need_augment <= 0:
                                break

                if loaded >= target_per_class:
                    break

            print(f"   âœ… åŠ è½½å®Œæˆ: {loaded} å¼ å›¾ç‰‡")
        else:
            print(f"   âš ï¸ é™Œç”Ÿäººç›®å½•ä¸å­˜åœ¨æˆ–ä¸ºç©º")
            # åˆ›å»ºä¸€äº›è™šæ‹Ÿçš„é™Œç”Ÿäººæ•°æ®
            for i in range(target_per_class):
                # åˆ›å»ºéšæœºå›¾åƒä½œä¸ºé™Œç”Ÿäººæ•°æ®
                random_img = np.random.randint(0, 255, (size, size, 3), dtype=np.uint8)
                imgs.append(random_img)

                label = [0] * num_classes
                label[-1] = 1
                labs.append(label)

            print(f"   âœ… ç”Ÿæˆè™šæ‹Ÿæ•°æ®: {target_per_class} å¼ å›¾ç‰‡")

        return np.array(imgs), np.array(labs), class_names


class FaceModelTrainer:
    """äººè„¸è¯†åˆ«æ¨¡å‹è®­ç»ƒå·¥å…·ç±»"""

    def __init__(self,
                 faces_ok_dir='./faces_ok',
                 faces_no_dir='./faces_no',
                 model_dir='./model_multi_class',
                 size=64,
                 batch_size=32,
                 learning_rate=0.001,
                 target_samples_per_class=400,
                 num_epochs=100,
                 patience=10):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨

        Args:
            faces_ok_dir: å·²çŸ¥äººè„¸æ•°æ®ç›®å½•
            faces_no_dir: é™Œç”Ÿäººæ•°æ®ç›®å½•
            model_dir: æ¨¡å‹ä¿å­˜ç›®å½•
            size: å›¾åƒå¤§å°
            batch_size: æ‰¹æ¬¡å¤§å°
            learning_rate: å­¦ä¹ ç‡
            target_samples_per_class: æ¯ç±»ç›®æ ‡æ ·æœ¬æ•°
            num_epochs: è®­ç»ƒè½®æ•°
            patience: æ—©åœè€å¿ƒå€¼
        """
        self.faces_ok_dir = faces_ok_dir
        self.faces_no_dir = faces_no_dir
        self.model_dir = model_dir
        self.size = size
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.target_samples = target_samples_per_class
        self.num_epochs = num_epochs
        self.patience = patience

        # è®­ç»ƒç»“æœ
        self.best_val_acc = 0
        self.train_losses = []
        self.val_accuracies = []
        self.class_names = []
        self.num_classes = 0

        # TensorFlowå ä½ç¬¦
        self.input_image = None
        self.input_label = None
        self.dropout_rate = None
        self.dropout_rate_2 = None
        self.outdata = None
        self.cross_entropy = None
        self.optimizer = None
        self.accuracy = None
        self.saver = None

    def check_directories(self):
        """æ£€æŸ¥å¿…è¦çš„ç›®å½•æ˜¯å¦å­˜åœ¨"""
        print("æ£€æŸ¥é¡¹ç›®ç›®å½•...")

        if not os.path.exists(self.faces_ok_dir):
            print(f"âŒ é”™è¯¯: {self.faces_ok_dir} ç›®å½•ä¸å­˜åœ¨")
            return False

        if not os.path.exists(self.faces_no_dir):
            print(f"âš ï¸ è­¦å‘Š: {self.faces_no_dir} ç›®å½•ä¸å­˜åœ¨ï¼Œå°†ç”Ÿæˆè™šæ‹Ÿé™Œç”Ÿäººæ•°æ®")
            os.makedirs(self.faces_no_dir, exist_ok=True)

        # åˆ›å»ºæ¨¡å‹ç›®å½•
        if os.path.exists(self.model_dir):
            print(f"âš ï¸ è­¦å‘Š: {self.model_dir} ç›®å½•å·²å­˜åœ¨ï¼Œå°†æ¸…ç©ºç›®å½•")
            shutil.rmtree(self.model_dir)

        os.makedirs(self.model_dir, exist_ok=True)
        print(f"âœ… æ¨¡å‹ç›®å½•åˆ›å»º: {self.model_dir}")

        return True

    def load_and_balance_data(self):
        """åŠ è½½å¹¶å¹³è¡¡æ•°æ®"""
        print("\nğŸ“¥ åŠ è½½æ•°æ®å¹¶å¹³è¡¡...")

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        data_loader = BalancedDataLoader(target_samples_per_class=self.target_samples)

        # åŠ è½½æ•°æ®
        imgs, labs, class_names = data_loader.load_balanced_data(
            self.faces_ok_dir, self.faces_no_dir, self.size
        )

        if imgs is None:
            print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
            return None, None, None, None, None

        self.class_names = class_names
        self.num_classes = len(class_names)

        print(f"\nğŸ“Š æœ€ç»ˆæ•°æ®ç»Ÿè®¡:")
        print(f"   æ€»å›¾ç‰‡æ•°: {len(imgs)}")

        # ç»Ÿè®¡å„ç±»åˆ«æ•°é‡
        lab_array = np.array(labs)
        for i in range(self.num_classes):
            count = np.sum(lab_array[:, i])
            print(f"   ç±»åˆ« {i} ({self.class_names[i]}): {count} å¼ ")

        return imgs, labs

    def preprocess_data(self, imgs, labs):
        """é¢„å¤„ç†æ•°æ®"""
        print(f"\nğŸ”€ åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†...")

        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        train_x, test_x, train_y, test_y = train_test_split(
            imgs, labs, test_size=0.2, random_state=42,
            stratify=np.argmax(labs, axis=1)  # åˆ†å±‚æŠ½æ ·
        )

        print(f"   è®­ç»ƒé›†: {len(train_x)} å¼ ")
        print(f"   æµ‹è¯•é›†: {len(test_x)} å¼ ")

        # å½’ä¸€åŒ–å’Œé‡å¡‘
        train_x = train_x.astype('float32') / 255.0
        test_x = test_x.astype('float32') / 255.0

        train_x = train_x.reshape(-1, self.size, self.size, 3)
        test_x = test_x.reshape(-1, self.size, self.size, 3)

        return train_x, test_x, train_y, test_y

    def build_model(self):
        """æ„å»ºæ¨¡å‹"""
        print(f"\nğŸ§  æ„å»ºç¥ç»ç½‘ç»œ...")

        # å®šä¹‰TensorFlowå ä½ç¬¦
        self.input_image = tf.compat.v1.placeholder(tf.float32, [None, self.size, self.size, 3])
        self.input_label = tf.compat.v1.placeholder(tf.float32, [None, self.num_classes])
        self.dropout_rate = tf.compat.v1.placeholder(tf.float32)
        self.dropout_rate_2 = tf.compat.v1.placeholder(tf.float32)

        # æ„å»ºç½‘ç»œ
        self.outdata = layer_net_tf1(self.input_image, self.num_classes,
                                     self.dropout_rate, self.dropout_rate_2)

        # å®šä¹‰æŸå¤±å‡½æ•°ï¼ˆå¸¦ç±»åˆ«æƒé‡ï¼‰
        class_weights = tf.constant([1.0] * self.num_classes, dtype=tf.float32)

        # è®¡ç®—åŠ æƒäº¤å‰ç†µæŸå¤±
        unweighted_loss = tf.nn.softmax_cross_entropy_with_logits(
            labels=self.input_label, logits=self.outdata
        )

        # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„æƒé‡
        sample_weights = tf.reduce_sum(self.input_label * class_weights, axis=1)
        weighted_loss = unweighted_loss * sample_weights
        self.cross_entropy = tf.reduce_mean(weighted_loss)

        # å®šä¹‰ä¼˜åŒ–å™¨
        self.optimizer = tf.compat.v1.train.AdamOptimizer(self.learning_rate).minimize(self.cross_entropy)

        # å®šä¹‰å‡†ç¡®ç‡è®¡ç®—
        correct_prediction = tf.equal(tf.argmax(self.outdata, 1), tf.argmax(self.input_label, 1))
        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

        # åˆ›å»ºSaver
        self.saver = tf.compat.v1.train.Saver(max_to_keep=3)

        print(f"âœ… æ¨¡å‹æ„å»ºå®Œæˆ")

    def train_model(self, train_x, train_y, test_x, test_y):
        """è®­ç»ƒæ¨¡å‹"""
        # è®­ç»ƒå‚æ•°
        num_batches = len(train_x) // self.batch_size

        # æ—©åœå‚æ•°
        best_val_acc = 0
        patience_counter = 0

        # è®­ç»ƒè®°å½•
        self.train_losses = []
        self.val_accuracies = []

        # åˆ›å»ºTensorFlowé…ç½®
        config = tf.compat.v1.ConfigProto(allow_soft_placement=True)
        config.gpu_options.allow_growth = True

        with tf.compat.v1.Session(config=config) as sess:
            # åˆå§‹åŒ–å˜é‡
            sess.run(tf.compat.v1.global_variables_initializer())

            print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ...")
            print(f"   è®­ç»ƒæ ·æœ¬: {len(train_x)}")
            print(f"   æµ‹è¯•æ ·æœ¬: {len(test_x)}")
            print(f"   æ‰¹æ¬¡å¤§å°: {self.batch_size}")
            print(f"   æ¯è½®æ‰¹æ¬¡: {num_batches}")
            print(f"   æœ€å¤§è½®æ¬¡: {self.num_epochs}")
            print(f"   æ—©åœè€å¿ƒå€¼: {self.patience}")

            # è®­ç»ƒå¾ªç¯
            for epoch in range(self.num_epochs):
                epoch_losses = []

                # æ‰“ä¹±è®­ç»ƒæ•°æ®
                indices = np.arange(len(train_x))
                np.random.shuffle(indices)
                train_x_shuffled = train_x[indices]
                train_y_shuffled = train_y[indices]

                # æ‰¹æ¬¡è®­ç»ƒ
                for batch_idx in range(num_batches):
                    start_idx = batch_idx * self.batch_size
                    end_idx = min((batch_idx + 1) * self.batch_size, len(train_x_shuffled))

                    batch_x = train_x_shuffled[start_idx:end_idx]
                    batch_y = train_y_shuffled[start_idx:end_idx]

                    # è®­ç»ƒæ­¥éª¤
                    _, loss = sess.run([self.optimizer, self.cross_entropy],
                                       feed_dict={self.input_image: batch_x,
                                                  self.input_label: batch_y,
                                                  self.dropout_rate: 0.5,
                                                  self.dropout_rate_2: 0.3})

                    epoch_losses.append(loss)

                # è®¡ç®—å¹³å‡æŸå¤±
                avg_loss = np.mean(epoch_losses)
                self.train_losses.append(avg_loss)

                # è®¡ç®—éªŒè¯å‡†ç¡®ç‡
                val_acc = self.accuracy.eval(feed_dict={
                    self.input_image: test_x,
                    self.input_label: test_y,
                    self.dropout_rate: 1.0,
                    self.dropout_rate_2: 1.0
                })
                self.val_accuracies.append(val_acc)

                # è¾“å‡ºè®­ç»ƒè¿›åº¦
                print(f"ğŸ“ è½®æ¬¡ {epoch + 1:3d}/{self.num_epochs} - "
                      f"æŸå¤±: {avg_loss:.4f} - "
                      f"éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}")

                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if val_acc > best_val_acc:
                    best_val_acc = val_acc
                    self.best_val_acc = best_val_acc
                    self.saver.save(sess, os.path.join(self.model_dir, 'best_model'))
                    print(f"   âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (å‡†ç¡®ç‡: {val_acc:.4f})")
                    patience_counter = 0

                    # ä¿å­˜æŸå¤±è®°å½•
                    with open(os.path.join(self.model_dir, 'loss.txt'), 'w') as f:
                        for loss_val in self.train_losses:
                            f.write(f"{loss_val}\n")
                else:
                    patience_counter += 1

                # æ—©åœæ£€æŸ¥
                if patience_counter >= self.patience:
                    print(f"\nğŸ›‘ æ—©åœè§¦å‘!")
                    print(f"   è¿ç»­ {self.patience} è½®éªŒè¯å‡†ç¡®ç‡æœªæå‡")
                    break

                # å¦‚æœå‡†ç¡®ç‡è¶³å¤Ÿé«˜ï¼Œæå‰åœæ­¢
                if val_acc > 0.95:
                    print(f"\nğŸ¯ è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡!")
                    break

            # ä¿å­˜æœ€ç»ˆæ¨¡å‹
            self.saver.save(sess, os.path.join(self.model_dir, 'final_model'))

            # ä¿å­˜ç±»åˆ«åç§°
            with open(os.path.join(self.model_dir, 'class_names.txt'), 'w', encoding='utf-8') as f:
                for name in self.class_names:
                    f.write(name + '\n')

            print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
            print(f"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")
            print(f"   æœ€ç»ˆæ¨¡å‹ä¿å­˜åˆ°: {self.model_dir}")

            # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
            if len(self.train_losses) > 1:
                self.plot_training_history()

            return True

    def plot_training_history(self):
        """ç»˜åˆ¶è®­ç»ƒå†å²æ›²çº¿"""
        try:
            plt.figure(figsize=(12, 4))

            plt.subplot(1, 2, 1)
            plt.plot(self.train_losses)
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.title('Training Loss')
            plt.grid(True)

            plt.subplot(1, 2, 2)
            plt.plot(self.val_accuracies)
            plt.xlabel('Epoch')
            plt.ylabel('Accuracy')
            plt.title('Validation Accuracy')
            plt.grid(True)

            plt.tight_layout()
            plt.savefig(os.path.join(self.model_dir, 'training_history.png'))
            plt.close()  # å…³é—­å›¾åƒï¼Œé¿å…é˜»å¡
            print(f"ğŸ“Š è®­ç»ƒæ›²çº¿ä¿å­˜åˆ°: {os.path.join(self.model_dir, 'training_history.png')}")
        except Exception as e:
            print(f"âš ï¸ ç»˜åˆ¶è®­ç»ƒæ›²çº¿å¤±è´¥: {e}")

    def train(self):
        """å®Œæ•´çš„è®­ç»ƒæµç¨‹"""
        try:
            print("=" * 60)
            print("          å¹³è¡¡æ•°æ®äººè„¸è¯†åˆ«æ¨¡å‹è®­ç»ƒ")
            print("=" * 60)

            # 1. æ£€æŸ¥ç›®å½•
            if not self.check_directories():
                return False

            # 2. åŠ è½½å’Œå¹³è¡¡æ•°æ®
            imgs, labs = self.load_and_balance_data()
            if imgs is None:
                return False

            # 3. é¢„å¤„ç†æ•°æ®
            train_x, test_x, train_y, test_y = self.preprocess_data(imgs, labs)

            # 4. æ„å»ºæ¨¡å‹
            self.build_model()

            # 5. è®­ç»ƒæ¨¡å‹
            success = self.train_model(train_x, train_y, test_x, test_y)

            if success:
                print(f"\nğŸ‰ æ‰€æœ‰è®­ç»ƒå®Œæˆ!")
                print(f"   æ¨¡å‹ä¿å­˜åœ¨: {self.model_dir}/")
                print(f"   ç±»åˆ«æ•°: {self.num_classes}")
                print(f"   ç±»åˆ«åç§°: {self.class_names}")

            return success

        except Exception as e:
            print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return False


# ä¸»ç¨‹åºå…¥å£ï¼ˆä¿ç•™ç”¨äºç‹¬ç«‹è¿è¡Œï¼‰
if __name__ == '__main__':
    """ç‹¬ç«‹è¿è¡Œè®­ç»ƒç¨‹åº"""

    # åˆ›å»ºè®­ç»ƒå™¨å®ä¾‹
    trainer = FaceModelTrainer(
        faces_ok_dir='./faces_ok',
        faces_no_dir='./faces_no',
        model_dir='./model_multi_class',
        size=64,
        batch_size=32,
        learning_rate=0.001,
        target_samples_per_class=400,
        num_epochs=100,
        patience=10
    )

    # å¼€å§‹è®­ç»ƒ
    success = trainer.train()

    if success:
        sys.exit(0)
    else:
        sys.exit(1)