"""--------------------------------------------------------------
äºŒã€CNNæ¨¡å‹è®­ç»ƒ - å¤šç±»åˆ«äººè„¸è¯†åˆ«ç‰ˆæœ¬ï¼ˆä¿®å¤ç‰ˆï¼‰
ä¿®å¤é—®é¢˜ï¼š
1. ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼ˆhsc:200, xsx:500, é™Œç”Ÿäºº:5000ï¼‰
2. åç½®ä¸å¹³è¡¡å¯¼è‡´æ€»æ˜¯è¯†åˆ«ä¸ºxsx
3. è¿‡æ‹Ÿåˆé—®é¢˜
------------------------------------------------------------------"""
import cv2
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
import shutil
import random
import os
import time
import matplotlib.pyplot as plt
import sys
import net
import units

# å¯ç”¨v1å…¼å®¹æ¨¡å¼
tf.compat.v1.disable_eager_execution()

# æ·»åŠ æ•°æ®å¹³è¡¡å’Œå¢å¼ºåŠŸèƒ½
class BalancedDataLoader:
    """å¹³è¡¡æ•°æ®åŠ è½½å™¨ï¼Œè§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜"""

    def __init__(self, target_samples_per_class=500):
        self.target_samples = target_samples_per_class
        self.augmentation_techniques = [
            self.horizontal_flip,
            self.adjust_brightness,
            self.adjust_contrast,
            self.random_rotation,
            self.add_noise
        ]

    def horizontal_flip(self, img):
        """æ°´å¹³ç¿»è½¬"""
        return cv2.flip(img, 1)

    def adjust_brightness(self, img):
        """è°ƒæ•´äº®åº¦"""
        alpha = random.uniform(0.7, 1.3)
        beta = random.randint(-30, 30)
        return cv2.convertScaleAbs(img, alpha=alpha, beta=beta)

    def adjust_contrast(self, img):
        """è°ƒæ•´å¯¹æ¯”åº¦"""
        alpha = random.uniform(0.8, 1.2)
        return cv2.convertScaleAbs(img, alpha=alpha, beta=0)

    def random_rotation(self, img):
        """éšæœºå°è§’åº¦æ—‹è½¬"""
        angle = random.uniform(-15, 15)
        h, w = img.shape[:2]
        center = (w // 2, h // 2)
        M = cv2.getRotationMatrix2D(center, angle, 1.0)
        return cv2.warpAffine(img, M, (w, h), borderMode=cv2.BORDER_REPLICATE)

    def add_noise(self, img):
        """æ·»åŠ é«˜æ–¯å™ªå£°"""
        noise = np.random.normal(0, 5, img.shape).astype(np.uint8)
        noisy_img = cv2.add(img, noise)
        return np.clip(noisy_img, 0, 255)

    def augment_image(self, img, num_augment=3):
        """å¢å¼ºå•å¼ å›¾ç‰‡"""
        augmented = [img]
        for _ in range(num_augment):
            # éšæœºé€‰æ‹©å¢å¼ºæŠ€æœ¯
            technique = random.choice(self.augmentation_techniques)
            try:
                aug_img = technique(img.copy())
                augmented.append(aug_img)
            except:
                # å¦‚æœå¢å¼ºå¤±è´¥ï¼Œä½¿ç”¨åŸå›¾
                augmented.append(img.copy())
        return augmented

    def load_balanced_data(self, faces_ok_dir, faces_no_dir, size=64):
        """åŠ è½½å¹¶å¹³è¡¡æ•°æ®"""
        imgs = []
        labs = []
        class_names = []

        # è·å–faces_okä¸‹çš„æ‰€æœ‰äººå‘˜ç›®å½•
        person_dirs = []
        for item in os.listdir(faces_ok_dir):
            item_path = os.path.join(faces_ok_dir, item)
            if os.path.isdir(item_path):
                person_dirs.append((item, item_path))
                class_names.append(item)

        if not person_dirs:
            print(f"é”™è¯¯: {faces_ok_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°äººå‘˜ç›®å½•")
            return None, None, None

        # æ·»åŠ é™Œç”Ÿäººç±»åˆ«
        class_names.append("é™Œç”Ÿäºº")
        num_classes = len(class_names)

        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   å·²çŸ¥äººå‘˜: {len(person_dirs)} äºº")
        print(f"   æ€»ç±»åˆ«æ•°: {num_classes}")

        # ç¬¬ä¸€æ­¥ï¼šç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„åŸå§‹å›¾ç‰‡æ•°é‡
        class_counts = {}
        for person_name, person_path in person_dirs:
            files = [f for f in os.listdir(person_path)
                    if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
            class_counts[person_name] = len(files)
            print(f"   {person_name}: {len(files)} å¼ åŸå§‹å›¾ç‰‡")

        # ç»Ÿè®¡é™Œç”Ÿäººå›¾ç‰‡æ•°é‡
        stranger_files = []
        if os.path.exists(faces_no_dir):
            stranger_files = [f for f in os.listdir(faces_no_dir)
                            if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        class_counts["é™Œç”Ÿäºº"] = len(stranger_files)
        print(f"   é™Œç”Ÿäºº: {len(stranger_files)} å¼ åŸå§‹å›¾ç‰‡")

        # ç¬¬äºŒæ­¥ï¼šç¡®å®šæ¯ä¸ªç±»åˆ«çš„ç›®æ ‡æ ·æœ¬æ•°
        # ä½¿ç”¨æœ€å°ç±»åˆ«çš„2å€ä½œä¸ºä¸Šé™ï¼Œç¡®ä¿å¹³è¡¡
        min_count = min(class_counts.values())
        target_per_class = min(self.target_samples, min_count * 2)
        print(f"\nâš–ï¸ å¹³è¡¡ç­–ç•¥:")
        print(f"   æœ€å°ç±»åˆ«æ ·æœ¬æ•°: {min_count}")
        print(f"   æ¯ç±»ç›®æ ‡æ ·æœ¬æ•°: {target_per_class}")

        # ç¬¬ä¸‰æ­¥ï¼šåŠ è½½å¹¶å¹³è¡¡å·²çŸ¥äººå‘˜æ•°æ®
        for idx, (person_name, person_path) in enumerate(person_dirs):
            print(f"\nğŸ“¥ åŠ è½½ {person_name} çš„æ•°æ®...")

            # è·å–è¯¥äººå‘˜çš„æ‰€æœ‰å›¾ç‰‡
            files = [f for f in os.listdir(person_path)
                    if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

            # å¦‚æœå›¾ç‰‡å¤ªå¤šï¼Œéšæœºé€‰æ‹©ä¸€éƒ¨åˆ†
            if len(files) > target_per_class:
                files = random.sample(files, target_per_class)

            loaded = 0
            need_augment = target_per_class - len(files)

            for file_idx, filename in enumerate(files):
                img_path = os.path.join(person_path, filename)
                img = cv2.imread(img_path)

                if img is not None:
                    # ç»Ÿä¸€å°ºå¯¸
                    img_resized = cv2.resize(img, (size, size))

                    # æ·»åŠ åŸå§‹å›¾ç‰‡
                    imgs.append(img_resized)

                    # åˆ›å»ºone-hotæ ‡ç­¾
                    label = [0] * num_classes
                    label[idx] = 1
                    labs.append(label)
                    loaded += 1

                    # å¦‚æœéœ€è¦å¢å¼ºä¸”æ˜¯å‰å‡ ä¸ªæ ·æœ¬
                    if need_augment > 0 and file_idx < min(20, len(files)):
                        # ä¸ºæ¯ä¸ªåŸå§‹å›¾ç‰‡åˆ›å»º2ä¸ªå¢å¼ºç‰ˆæœ¬
                        augmented_imgs = self.augment_image(img_resized, num_augment=2)
                        for aug_img in augmented_imgs[1:]:  # è·³è¿‡åŸå§‹å›¾ç‰‡
                            imgs.append(aug_img)
                            labs.append(label.copy())
                            loaded += 1
                            need_augment -= 1
                            if need_augment <= 0:
                                break

                if loaded >= target_per_class:
                    break

            print(f"   âœ… åŠ è½½å®Œæˆ: {loaded} å¼ å›¾ç‰‡")

        # ç¬¬å››æ­¥ï¼šåŠ è½½å¹¶å¹³è¡¡é™Œç”Ÿäººæ•°æ®
        print(f"\nğŸ“¥ åŠ è½½é™Œç”Ÿäººæ•°æ®...")
        if os.path.exists(faces_no_dir) and stranger_files:
            # å¦‚æœé™Œç”Ÿäººå›¾ç‰‡å¤ªå¤šï¼Œéšæœºé€‰æ‹©
            if len(stranger_files) > target_per_class:
                selected_files = random.sample(stranger_files, target_per_class)
            else:
                selected_files = stranger_files

            loaded = 0
            need_augment = target_per_class - len(selected_files)

            for file_idx, filename in enumerate(selected_files):
                img_path = os.path.join(faces_no_dir, filename)
                img = cv2.imread(img_path)

                if img is not None:
                    # ç»Ÿä¸€å°ºå¯¸
                    img_resized = cv2.resize(img, (size, size))

                    # æ·»åŠ åŸå§‹å›¾ç‰‡
                    imgs.append(img_resized)

                    # åˆ›å»ºone-hotæ ‡ç­¾ï¼ˆæœ€åä¸€ä¸ªç±»åˆ«ï¼‰
                    label = [0] * num_classes
                    label[-1] = 1
                    labs.append(label)
                    loaded += 1

                    # å¦‚æœéœ€è¦å¢å¼º
                    if need_augment > 0 and file_idx < min(20, len(selected_files)):
                        augmented_imgs = self.augment_image(img_resized, num_augment=2)
                        for aug_img in augmented_imgs[1:]:
                            imgs.append(aug_img)
                            labs.append(label.copy())
                            loaded += 1
                            need_augment -= 1
                            if need_augment <= 0:
                                break

                if loaded >= target_per_class:
                    break

            print(f"   âœ… åŠ è½½å®Œæˆ: {loaded} å¼ å›¾ç‰‡")
        else:
            print(f"   âš ï¸ é™Œç”Ÿäººç›®å½•ä¸å­˜åœ¨æˆ–ä¸ºç©º")
            # åˆ›å»ºä¸€äº›è™šæ‹Ÿçš„é™Œç”Ÿäººæ•°æ®
            for i in range(target_per_class):
                # åˆ›å»ºéšæœºå›¾åƒä½œä¸ºé™Œç”Ÿäººæ•°æ®
                random_img = np.random.randint(0, 255, (size, size, 3), dtype=np.uint8)
                imgs.append(random_img)

                label = [0] * num_classes
                label[-1] = 1
                labs.append(label)

            print(f"   âœ… ç”Ÿæˆè™šæ‹Ÿæ•°æ®: {target_per_class} å¼ å›¾ç‰‡")

        return np.array(imgs), np.array(labs), class_names

"""å®šä¹‰è®­ç»ƒå‡½æ•° - æ”¹è¿›ç‰ˆ"""
def do_train(outdata, cross_entropy, optimizer, num_classes, class_names,
             train_x, train_y, test_x, test_y, batch_size=32):
    """æ”¹è¿›çš„è®­ç»ƒå‡½æ•°ï¼ŒåŒ…å«æ—©åœå’Œæ¨¡å‹ä¿å­˜"""

    # å®šä¹‰å‡†ç¡®ç‡è®¡ç®—
    correct_prediction = tf.equal(tf.argmax(outdata, 1), tf.argmax(input_label, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

    # åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
    model_dir = './model_balanced'
    if not os.path.exists(model_dir):
        os.makedirs(model_dir)

    # ä¿å­˜ç±»åˆ«åç§°
    with open(os.path.join(model_dir, 'class_names.txt'), 'w', encoding='utf-8') as f:
        for name in class_names:
            f.write(name + '\n')

    # è®­ç»ƒå‚æ•°
    num_epochs = 100
    num_batches = len(train_x) // batch_size

    # æ—©åœå‚æ•°
    patience = 10
    best_val_acc = 0
    patience_counter = 0

    # è®°å½•è®­ç»ƒè¿‡ç¨‹
    train_losses = []
    val_accuracies = []

    # åˆ›å»ºSaver
    saver = tf.compat.v1.train.Saver(max_to_keep=3)

    # åˆ›å»ºTensorFlowé…ç½®
    config = tf.compat.v1.ConfigProto(allow_soft_placement=True)
    config.gpu_options.allow_growth = True

    with tf.compat.v1.Session(config=config) as sess:
        # åˆå§‹åŒ–å˜é‡
        sess.run(tf.compat.v1.global_variables_initializer())

        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ...")
        print(f"   è®­ç»ƒæ ·æœ¬: {len(train_x)}")
        print(f"   æµ‹è¯•æ ·æœ¬: {len(test_x)}")
        print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
        print(f"   æ¯è½®æ‰¹æ¬¡: {num_batches}")
        print(f"   æœ€å¤§è½®æ¬¡: {num_epochs}")
        print(f"   æ—©åœè€å¿ƒå€¼: {patience}")

        # è®­ç»ƒå¾ªç¯
        for epoch in range(num_epochs):
            epoch_losses = []

            # æ‰“ä¹±è®­ç»ƒæ•°æ®
            indices = np.arange(len(train_x))
            np.random.shuffle(indices)
            train_x_shuffled = train_x[indices]
            train_y_shuffled = train_y[indices]

            # æ‰¹æ¬¡è®­ç»ƒ
            for batch_idx in range(num_batches):
                start_idx = batch_idx * batch_size
                end_idx = min((batch_idx + 1) * batch_size, len(train_x_shuffled))

                batch_x = train_x_shuffled[start_idx:end_idx]
                batch_y = train_y_shuffled[start_idx:end_idx]

                # è®­ç»ƒæ­¥éª¤
                _, loss = sess.run([optimizer, cross_entropy],
                                  feed_dict={input_image: batch_x,
                                            input_label: batch_y,
                                            dropout_rate: 0.5,
                                            dropout_rate_2: 0.3})

                epoch_losses.append(loss)

            # è®¡ç®—å¹³å‡æŸå¤±
            avg_loss = np.mean(epoch_losses)
            train_losses.append(avg_loss)

            # è®¡ç®—éªŒè¯å‡†ç¡®ç‡
            val_acc = accuracy.eval(feed_dict={
                input_image: test_x,
                input_label: test_y,
                dropout_rate: 1.0,
                dropout_rate_2: 1.0
            })
            val_accuracies.append(val_acc)

            # è¾“å‡ºè®­ç»ƒè¿›åº¦
            print(f"ğŸ“ è½®æ¬¡ {epoch+1:3d}/{num_epochs} - "
                  f"æŸå¤±: {avg_loss:.4f} - "
                  f"éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}")

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                saver.save(sess, os.path.join(model_dir, 'best_model'))
                print(f"   âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (å‡†ç¡®ç‡: {val_acc:.4f})")
                patience_counter = 0

                # ä¿å­˜æŸå¤±è®°å½•
                with open(os.path.join(model_dir, 'loss.txt'), 'w') as f:
                    for loss_val in train_losses:
                        f.write(f"{loss_val}\n")
            else:
                patience_counter += 1

            # æ—©åœæ£€æŸ¥
            if patience_counter >= patience:
                print(f"\nğŸ›‘ æ—©åœè§¦å‘!")
                print(f"   è¿ç»­ {patience} è½®éªŒè¯å‡†ç¡®ç‡æœªæå‡")
                break

            # å¦‚æœå‡†ç¡®ç‡è¶³å¤Ÿé«˜ï¼Œæå‰åœæ­¢
            if val_acc > 0.95:
                print(f"\nğŸ¯ è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡!")
                break

        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        saver.save(sess, os.path.join(model_dir, 'final_model'))

        print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
        print(f"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")
        print(f"   æœ€ç»ˆæ¨¡å‹ä¿å­˜åˆ°: {model_dir}")

        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        if len(train_losses) > 1:
            plt.figure(figsize=(12, 4))

            plt.subplot(1, 2, 1)
            plt.plot(train_losses)
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.title('Training Loss')
            plt.grid(True)

            plt.subplot(1, 2, 2)
            plt.plot(val_accuracies)
            plt.xlabel('Epoch')
            plt.ylabel('Accuracy')
            plt.title('Validation Accuracy')
            plt.grid(True)

            plt.tight_layout()
            plt.savefig(os.path.join(model_dir, 'training_history.png'))
            plt.show()

        # è¾“å‡ºæ¨¡å‹åç½®ä¿¡æ¯ï¼ˆè¯Šæ–­ç”¨ï¼‰
        all_vars = tf.compat.v1.global_variables()
        for var in all_vars:
            if 'b5:0' in var.name:  # è¾“å‡ºå±‚åç½®
                bias_value = sess.run(var)
                print(f"\nğŸ“Š è¾“å‡ºå±‚åç½®:")
                for i, bias in enumerate(bias_value):
                    class_name = class_names[i] if i < len(class_names) else f"Class_{i}"
                    print(f"   {class_name}: {bias:.4f}")

if __name__ == '__main__':
    """ä¸»å‡½æ•° - ä¿®å¤ç‰ˆ"""

    print("=" * 60)
    print("          å¹³è¡¡æ•°æ®äººè„¸è¯†åˆ«æ¨¡å‹è®­ç»ƒ")
    print("=" * 60)

    # å®šä¹‰å‚æ•°
    faces_ok_dir = './faces_ok'
    faces_no_dir = './faces_no'
    size = 64
    batch_size = 32
    learning_rate = 0.001

    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(faces_ok_dir):
        print(f"âŒ é”™è¯¯: {faces_ok_dir} ç›®å½•ä¸å­˜åœ¨")
        sys.exit(1)

    if not os.path.exists(faces_no_dir):
        print(f"âš ï¸ è­¦å‘Š: {faces_no_dir} ç›®å½•ä¸å­˜åœ¨ï¼Œå°†ç”Ÿæˆè™šæ‹Ÿé™Œç”Ÿäººæ•°æ®")
        os.makedirs(faces_no_dir, exist_ok=True)

    # 1. ä½¿ç”¨å¹³è¡¡æ•°æ®åŠ è½½å™¨åŠ è½½æ•°æ®
    print("\nğŸ“¥ åŠ è½½æ•°æ®å¹¶å¹³è¡¡...")
    data_loader = BalancedDataLoader(target_samples_per_class=400)  # æ¯ç±»ç›®æ ‡400å¼ 
    imgs, labs, class_names = data_loader.load_balanced_data(faces_ok_dir, faces_no_dir, size)

    if imgs is None:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
        sys.exit(1)

    num_classes = len(class_names)
    print(f"\nğŸ“Š æœ€ç»ˆæ•°æ®ç»Ÿè®¡:")
    print(f"   æ€»å›¾ç‰‡æ•°: {len(imgs)}")

    # ç»Ÿè®¡å„ç±»åˆ«æ•°é‡
    lab_array = np.array(labs)
    for i in range(num_classes):
        count = np.sum(lab_array[:, i])
        print(f"   ç±»åˆ« {i} ({class_names[i]}): {count} å¼ ")

    # 2. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    print(f"\nğŸ”€ åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†...")
    train_x, test_x, train_y, test_y = train_test_split(
        imgs, labs, test_size=0.2, random_state=42,
        stratify=np.argmax(labs, axis=1)  # åˆ†å±‚æŠ½æ ·
    )

    print(f"   è®­ç»ƒé›†: {len(train_x)} å¼ ")
    print(f"   æµ‹è¯•é›†: {len(test_x)} å¼ ")

    # 3. å½’ä¸€åŒ–å’Œé‡å¡‘
    train_x = train_x.astype('float32') / 255.0
    test_x = test_x.astype('float32') / 255.0

    train_x = train_x.reshape(-1, size, size, 3)
    test_x = test_x.reshape(-1, size, size, 3)

    # 4. å®šä¹‰TensorFlowå›¾
    input_image = tf.compat.v1.placeholder(tf.float32, [None, size, size, 3])
    input_label = tf.compat.v1.placeholder(tf.float32, [None, num_classes])
    dropout_rate = tf.compat.v1.placeholder(tf.float32)
    dropout_rate_2 = tf.compat.v1.placeholder(tf.float32)

    # 5. æ„å»ºç½‘ç»œ - ä¿®æ”¹åˆå§‹åŒ–ä»¥å‡å°‘åç½®ä¸å¹³è¡¡
    print(f"\nğŸ§  æ„å»ºç¥ç»ç½‘ç»œ...")

    # è·å–ç½‘ç»œè¾“å‡º
    outdata = net.layer_net(input_image, num_classes, dropout_rate, dropout_rate_2)

    # 6. å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    # æ·»åŠ ç±»åˆ«æƒé‡ï¼ˆç»™æ ·æœ¬å°‘çš„ç±»åˆ«æ›´é«˜æƒé‡ï¼‰
    class_weights = tf.constant([1.0] * num_classes, dtype=tf.float32)

    # è®¡ç®—åŠ æƒäº¤å‰ç†µæŸå¤±
    unweighted_loss = tf.nn.softmax_cross_entropy_with_logits(
        labels=input_label, logits=outdata
    )

    # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„æƒé‡
    sample_weights = tf.reduce_sum(input_label * class_weights, axis=1)
    weighted_loss = unweighted_loss * sample_weights
    cross_entropy = tf.reduce_mean(weighted_loss)

    # ä½¿ç”¨Adamä¼˜åŒ–å™¨
    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate).minimize(cross_entropy)

    # 7. å¼€å§‹è®­ç»ƒ
    do_train(outdata, cross_entropy, optimizer, num_classes, class_names,
             train_x, train_y, test_x, test_y, batch_size)

    print(f"\nğŸ‰ æ‰€æœ‰è®­ç»ƒå®Œæˆ!")
    print(f"   æ¨¡å‹ä¿å­˜åœ¨: ./model_balanced/")
    print(f"   ä½¿ç”¨æ–°æ¨¡å‹è¿›è¡Œè¯†åˆ«æ—¶ï¼Œè¯·ä¿®æ”¹è¯†åˆ«è„šæœ¬ä¸­çš„æ¨¡å‹è·¯å¾„")